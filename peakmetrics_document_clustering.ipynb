{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd2dea",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from itertools import combinations\n",
    "import swifter\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import peakmetrics_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d53570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news.pickle','rb') as f:\n",
    "    news=json.load(f, orient='records')\n",
    "with open('social.pickle','rb') as f:\n",
    "    social=pickle.load(f)\n",
    "with open('blog.pickle','rb') as f:\n",
    "    blog=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbdc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate record indeces for use by Louvain community detection algorithm --- has to be done twice because reasons\n",
    "blog=blog.reset_index()\n",
    "del(blog['index'])\n",
    "blog=blog.reset_index()\n",
    "news=news.reset_index()\n",
    "del(news['index'])\n",
    "news=news.reset_index()\n",
    "social=social.reset_index()\n",
    "del(social['index'])\n",
    "social=social.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162786b4",
   "metadata": {},
   "source": [
    "### Blog data Louvain community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48024ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_edges=list(combinations(blog['index'].to_list(),2))\n",
    "blog_edges=[(x[0],x[1],blog.loc[x[0]]['minilm_embeddings'],blog.loc[x[1]]['minilm_embeddings']) for x in tqdm(blog_edges, position=0)]\n",
    "blog_edges=pd.DataFrame(blog_edges,columns=['node_1','node_2','vectors_1','vectors_2'])\n",
    "blog_edges['proximity']=blog_edges.swifter.apply(lambda x: util.pytorch_cos_sim(x['vectors_1'],x['vectors_2'])[0][0].item(), axis=1)\n",
    "\n",
    "tik=time()\n",
    "blog_G=peakmetrics_utilities.find_louvain_communities(blog_edges)\n",
    "tok=time()\n",
    "\n",
    "tok-tik\n",
    "blog['community']=blog_G['community']\n",
    "blog['cluster']=-2\n",
    "import pickle\n",
    "with open('blog_clustered.pickle','wb') as f:\n",
    "    pickle.dump(blog, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d742618",
   "metadata": {},
   "source": [
    "### News and Social media clustering --- negative records only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a61dfd",
   "metadata": {},
   "source": [
    "#### News media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce490bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_neg=news[news['sentiment_label']=='negative']\n",
    "news_neg=news_neg.reset_index()\n",
    "del(news_neg['index'])\n",
    "news_neg=news_neg.reset_index()\n",
    "\n",
    "social_neg=social[social['sentiment_label']=='negative']\n",
    "social_neg=social_neg.reset_index()\n",
    "del(social_neg['index'])\n",
    "social_neg=social_neg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50adae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_edges=list(combinations(news_neg['index'].to_list(),2))\n",
    "news_edges=[(x[0],x[1],news_neg.iloc[x[0]]['minilm_embeddings'],news.iloc[x[1]]['minilm_embeddings']) for x in tqdm(news_edges, position=0)]\n",
    "news_edges=pd.DataFrame(news_edges,columns=['node_1','node_2','vectors_1','vectors_2'])\n",
    "news_edges['proximity']=news_edges.swifter.apply(lambda x: util.pytorch_cos_sim(x['vectors_1'],x['vectors_2'])[0][0].item(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tik=time()\n",
    "news_neg_G=peakmetrics_utilities.find_louvain_communities(news_edges)\n",
    "tok=time()\n",
    "\n",
    "print(tok-tik)\n",
    "print(news_neg_G['community'].value_counts(normalize=True))\n",
    "news_neg['community']=news_neg_G['community']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_neg_embeds=news_neg['minilm_embeddings']\n",
    "news_neg_embeds=np.array([np.array(y) for y in news_neg_embeds])\n",
    "news_neg_random_use=random_search(news_embeds, space, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a201b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_neg_random_use.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1825d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_neg_cluster_labels = generate_clusters(news_neg_embeds, \n",
    "                                     n_neighbors = 31, \n",
    "                                     n_components = 11,\n",
    "                                     min_cluster_size = 8, \n",
    "                                     random_state = 42)\n",
    "news_neg['clusters']=news_neg_cluster_labels.labels_\n",
    "print(news_neg['clusters'].value_counts(normalize=True).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('news_neg_clustered.pickle','wb') as f:\n",
    "    pickle.dump(news_neg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3adf2",
   "metadata": {},
   "source": [
    "#### Social media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_edges=list(combinations(social_neg['index'].to_list(),2))\n",
    "social_edges=[(x[0],x[1],social.iloc[x[0]]['minilm_embeddings'],social.iloc[x[1]]['minilm_embeddings']) for x in tqdm(social_edges, position=0)]\n",
    "social_edges=pd.DataFrame(social_edges,columns=['node_1','node_2','vectors_1','vectors_2'])\n",
    "social_edges['proximity']=social_edges.swifter.apply(lambda x: util.pytorch_cos_sim(x['vectors_1'],x['vectors_2'])[0][0].item(), axis=1)\n",
    "tik=time()\n",
    "social_neg_G=peakmetrics_utilities.find_louvain_communities(social_edges)\n",
    "tok=time()\n",
    "\n",
    "print(tok-tik)\n",
    "social_neg['community']=social_neg_G['community']\n",
    "print(social_neg_G['community'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_neg_embeds=social_neg['minilm_embeddings']\n",
    "social_neg_embeds=np.array([np.array(y) for y in social_neg_embeds])\n",
    "social_neg_random_use=random_search(social_neg_embeds, space, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec0ade",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "social_neg_random_use.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_neg_cluster_labels = generate_clusters(social_neg_embeds, \n",
    "                                     n_neighbors = 54, \n",
    "                                     n_components = 13, \n",
    "                                     min_cluster_size = 27, \n",
    "                                     random_state = 42)\n",
    "social_neg['clusters']=social_neg_cluster_labels.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('social_neg_clustered.pickle','wb') as f:\n",
    "    pickle.dump(social_neg, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
